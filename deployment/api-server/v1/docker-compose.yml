version: '2.1'
services:
    # ========== DATABASE ==========
    mysql:
        image: mysql:${MYSQL_TAG}
        container_name: mysql
        ports:
            - "${MYSQL_PORT}:${MYSQL_PORT}"
        logging:
            options:
                max-size: "${DOCKER_LOG_OPT_MAX_SIZE}"
                max-file: ${DOCKER_LOG_OPT_MAX_FILE}
        environment:
            MYSQL_ROOT_PASSWORD: ${MYSQL_MAIN_PASS}
        mem_limit: 5125m
        volumes:
            - ./database/mysql/my.cnf:/etc/mysql/my.cnf
            - ./database/mysql/emotibot.sql:/var/local/database/emotibot.sql
            - ./database/mysql/voice_emotion.sql:/var/local/database/voice_emotion.sql
            - ./database/mysql/authentication.sql:/var/local/database/authentication.sql
            - ./database/mysql/privilege_init.sql:/var/local/database/privilege_init.sql
            - ./database/mysql/docker-entrypoint.sh:/usr/local/bin/docker-entrypoint.sh
            - ${MYSQL_DATA_PATH}:/var/lib/mysql
            - /etc/localtime:/etc/localtime
        restart: always
        healthcheck:
            test: "/usr/bin/mysql --user=${MYSQL_MAIN_USER} --password=${MYSQL_MAIN_PASS} --execute \"SHOW DATABASES;\""
            interval: "${DOCKER_HEALTH_CHECK_INTERVAL}"
            timeout: "${DOCKER_HEALTH_CHECK_TIMEOUT}" 
            retries: 5
    phpmyadmin:
        image: phpmyadmin/phpmyadmin
        container_name: phpmyadmin
        ports:
            - "${PHPMYADMIN_PORT}:80"
        logging:
            options:
                max-size: "${DOCKER_LOG_OPT_MAX_SIZE}"
                max-file: ${DOCKER_LOG_OPT_MAX_FILE}
        mem_limit: 5125m
        environment:
            MYSQL_USERNAME: ${MYSQL_MAIN_USER}
            MYSQL_PASSWORD: ${MYSQL_MAIN_PASS}
        volumes:
            - /etc/localtime:/etc/localtime
        links:
            - mysql:db
        restart: always
        depends_on:
            "mysql":
                condition: service_healthy
    mongo:
        image: mongo:3.2.8
        container_name: "mongo"
        environment:
            - MONGO_DATA_DIR=/data/db
            - MONGO_LOG_DIR=/dev/null
        volumes:
            - "${MONGO_DATA_PATH}:/data/db"
        ports:
            - "${MONGO_PORT}:${MONGO_PORT}"
        logging:
            options:
                max-size: "${DOCKER_LOG_OPT_MAX_SIZE}"
                max-file: ${DOCKER_LOG_OPT_MAX_FILE}
        restart: always
        healthcheck:
            test: "mongo --quiet \"${MONGO_IP}/test\" --eval 'quit(db.runCommand({ ping: 1 }).ok ? 0 : 2)'"
            interval: "${DOCKER_HEALTH_CHECK_INTERVAL}"
            timeout: "${DOCKER_HEALTH_CHECK_TIMEOUT}" 
            retries: 5
    # ========== Queue ==========
    rabbitmq:
        image: rabbitmq:${RABBITMQ_TAG}
        hostname: "my-rabbit"
        container_name: "rabbitmq"
        ports:
            - "${RABBITMQ_PORT}:${RABBITMQ_PORT}"
        logging:
            options:
                max-size: "${DOCKER_LOG_OPT_MAX_SIZE}"
                max-file: ${DOCKER_LOG_OPT_MAX_FILE}
        mem_limit: 5125m
        volumes:
            - ${RABBITMQ_DATA_PATH}:/var/lib/rabbitmq
            - /etc/localtime:/etc/localtime
        restart: always
        healthcheck:
            test: "exit 0"
    # ========== Voice Emotion APIs: depends on rabbitmq/mysql
    api-voice-emotion:
        image: ${API_VOICE_EMOTION_IMAGE}:${API_VOICE_EMOTION_TAG}
        container_name: ${API_VOICE_EMOTION_CONTAINER}
        ports:
            - "${API_VOICE_EMOTION_PORT}:${API_VOICE_EMOTION_PORT}"
        logging:
            options:
                max-size: "${DOCKER_LOG_OPT_MAX_SIZE}"
                max-file: ${DOCKER_LOG_OPT_MAX_FILE}
        mem_limit: 5125m
        environment:
            RABBITMQ_HOST: ${API_VOICE_EMOTION_RABBITMQ_HOST}
            RABBITMQ_PORT: ${API_VOICE_EMOTION_RABBITMQ_PORT}
            RABBITMQ_USER: ${API_VOICE_EMOTION_RABBITMQ_USER}
            RABBITMQ_PWD: ${API_VOICE_EMOTION_RABBITMQ_PWD}
            DB_HOST: ${API_VOICE_EMOTION_DB_HOST}
            DB_PORT: ${API_VOICE_EMOTION_DB_PORT}
            DB_USER: ${API_VOICE_EMOTION_DB_USER}
            DB_PWD: ${API_VOICE_EMOTION_DB_PWD}
            LISTEN_PORT: ${API_VOICE_EMOTION_PORT}
            FILE_PREFIX: ${API_VOICE_EMOTION_DATA_PATH}
        volumes:
            - ${API_VOICE_EMOTION_DATA_PATH}:/usr/src/app/upload_file
            - /etc/localtime:/etc/localtime
        restart: always
        depends_on:
            "mysql":
                condition: service_healthy
            "rabbitmq":
                condition: service_healthy





    # ========== Voice Emotion Analysis Worker: depends on rabbitmq  (worker-voice-emotion-analysis)
    w-v-emotion:
        image: ${WORKER_VOICE_EMOTION_ANA_IMAGE}:${WORKER_VOICE_EMOTION_ANA_TAG}
        # container_name: ${WORKER_VOICE_EMOTION_ANA_CONTAINER}-1
        mem_limit: 4096m
        logging:
            options:
                max-size: "${DOCKER_LOG_OPT_MAX_SIZE}"
                max-file: ${DOCKER_LOG_OPT_MAX_FILE}
        environment:
            ENV_KEY_MONGODB_ENABLE: "true"
            ENV_KEY_MONGODB_HOST_IP: ${WORKER_VOICE_EMOTION_ANA_MONGO_HOST}
            ENV_KEY_MONGODB_HOST_PORT: ${WORKER_VOICE_EMOTION_ANA_MONGO_PORT}
            ENV_KEY_MONGODB_DATABASE_NAME: ${WORKER_VOICE_EMOTION_ANA_MONGO_DB_NAME}
            ENV_KEY_MONGODB_SAVE_RESULT_INFO: "true"
            ENV_KEY_MONGODB_RESULT_COLLECTION_NAME: ${WORKER_VOICE_EMOTION_ANA_MONGO_RET_COLLECTION_NAME}
            ENV_KEY_MONGODB_SAVE_DETAILS_INFO: "true"
            ENV_KEY_MONGODB_DETAILS_COLLECTION_NAME: ${WORKER_VOICE_EMOTION_ANA_MONGO_DETAIL_COLLECTION_NAME}
            ENV_KEY_RABBITMQ_TASK_QUEUE_HOST_IP: ${WORKER_VOICE_EMOTION_ANA_RABBITMQ_HOST}
            ENV_KEY_RABBITMQ_TASK_QUEUE_HOST_PORT: ${WORKER_VOICE_EMOTION_ANA_RABBITMQ_PORT}
            ENV_KEY_RABBITMQ_TASK_QUEUE_NAME: ${WORKER_VOICE_EMOTION_ANA_RABBITMQ_TASK}
            ENV_KEY_RABBITMQ_RESULT_QUEUE_NAME: ${WORKER_VOICE_EMOTION_ANA_RABBITMQ_RESULT}
            ENV_KEY_KEEP_VOICE_INTERMEDIATES_WHEN_ERR: "false"
            ENV_KEY_ALWAYS_USE_NEW_WORKERS: "false"
            ENV_KEY_SAVE_FEATURE_EXTRACT_RESULT_TO_DB: "false"
            ENV_KEY_INPUT_WAV_LENGTH_MIN_THRESHOLD_IN_MILLISECONDS: "${WORKER_VOICE_EMOTION_ANA_LENGTH_MIN_LIMITATION}"
            ENV_KEY_ENABLE_GLUSTERFS: "${WORKER_VOICE_EMOTION_ANA_ENABLE_GLUSTERFS}"
            ENV_KEY_GLUSTERFS_VOLUME_MOUNT_PATH: "${WORKER_VOICE_EMOTION_ANA_GLUSTERFS_VOLUME_MOUNT_PATH}"
            ENV_KEY_MAX_SERVANTS: 6
            ENV_KEY_ASR_ENABLE: ${WORKER_ENV_KEY_ASR_ENABLE}
            ENV_KEY_ASR_OUTPUT_QUEUE_HOST_IP: ${WORKER_ENV_KEY_ASR_OUTPUT_QUEUE_HOST_IP}
            ENV_KEY_ASR_OUTPUT_QUEUE_HOST_PORT: ${WORKER_ENV_KEY_ASR_OUTPUT_QUEUE_HOST_PORT}
            ENV_KEY_ASR_OUTPUT_QUEUE_NAME: ${WORKER_ENV_KEY_ASR_OUTPUT_QUEUE_NAME}


        volumes:
            - ${WORKER_VOICE_EMOTION_ANA_DATA_PATH}:/usr/src/app/output
            - ${WORKER_VOICE_EMOTIOM_ANA_INPUT_DATA_PATH}:${WORKER_VOICE_EMOTIOM_ANA_INPUT_DATA_PATH}
            - ${WORKER_VOICE_ASR_SHARED_FOLDER}:/usr/src/app/shared_asr     ## The mount path must shared with "w-v-asr"
        restart: always
        depends_on:
            "rabbitmq":
                condition: service_healthy
            "mongo":
                condition: service_healthy



    # ========== ASR Workers: depends on rabbitmq/mysql/w-v-emotion(VoiceEmotionAnalysisWorker)
    # ASR Models will exhaust lots memory which need you to pay attention on whether the memory limit is reached
    w-v-asr:
        image: ${WORKER_VOICE_ASR_IMAGE}:${WORKER_VOICE_ASR_TAG}
	# ASR model is very big which will eat lots of memory. Not enough memory will result in system very low or fail.
	# mem_limit will depend on how many worker processes you create in the docker. 500MB for each one. You can custom with the param : WORKER_ENV_KEY_ASR_MAX_WORKERS
        mem_limit: 8192m   
        logging:
            options:
                max-size: "${DOCKER_LOG_OPT_MAX_SIZE}"
                max-file: ${DOCKER_LOG_OPT_MAX_FILE}
        environment:
            ENV_KEY_ASR_ORM_DBG_FLAG: "true"
            ENV_KEY_ASR_MAX_WORKERS:                ${WORKER_ENV_KEY_ASR_MAX_WORKERS}
            ENV_KEY_ASR_RABBITMQ_HOST_IP:           ${WORKER_ENV_KEY_ASR_OUTPUT_QUEUE_HOST_IP}          # Must the same ip with the w-v-emotion
            ENV_KEY_ASR_RABBITMQ_HOST_PORT:         ${WORKER_ENV_KEY_ASR_OUTPUT_QUEUE_HOST_PORT}        # Must the same port with the w-v-emotion
            ENV_KEY_ASR_RABBITMQ_TASK_QUEUE_NAME:   ${WORKER_ENV_KEY_ASR_OUTPUT_QUEUE_NAME}             # Must the same queue with the w-v-emotion
            ENV_KEY_ASR_DATABASE_IP:                ${WORKER_ENV_KEY_ASR_DATABASE_IP}
            ENV_KEY_ASR_N_OF_N_BEST:                ${WORKER_ENV_KEY_ASR_N_OF_N_BEST}
            ENV_KEY_ASR_DATABASE_NAME:              ${WORKER_ENV_KEY_ASR_DATABASE_NAME}
            ENV_KEY_ASR_DATABASE_PORT:              ${MYSQL_PORT}
            ENV_KEY_ASR_DATABASE_USER_NAME:         ${MYSQL_MAIN_USER}
            ENV_KEY_ASR_DATABASE_PWD:               ${MYSQL_MAIN_PASS}

        volumes:
            - ${WORKER_VOICE_ASR_DATA_PATH}:/usr/src/app/main/output           # logs output path
            - ${WORKER_VOICE_ASR_SHARED_FOLDER}:/usr/src/app/main/shared_asr    # The mount path must shared with "w-v-emotion"
        restart: always
        depends_on:
            "mysql":
                condition: service_healthy
            "rabbitmq":
                condition: service_healthy












    # ========== Voice Emotion Statistic Worker: depends on rabbitmq/mysql
    worker-voice-emotion-statistic:
        image: ${WORKER_VOICE_EMOTION_STATISTIC_IMAGE}:${WORKER_VOICE_EMOTION_STATISTIC_TAG}
        container_name: ${WORKER_VOICE_EMOTION_STATISTIC_CONTAINER}
        logging:
            options:
                max-size: "${DOCKER_LOG_OPT_MAX_SIZE}"
                max-file: ${DOCKER_LOG_OPT_MAX_FILE}
        mem_limit: 2048m
        environment:
            RABBITMQ_HOST: ${WORKER_VOICE_EMOTION_STATISTIC_RABBITMQ_HOST}
            RABBITMQ_PORT: ${WORKER_VOICE_EMOTION_STATISTIC_RABBITMQ_PORT}
            RABBITMQ_USER: ${WORKER_VOICE_EMOTION_STATISTIC_RABBITMQ_USER}
            RABBITMQ_PWD: ${WORKER_VOICE_EMOTION_STATISTIC_RABBITMQ_PWD}
            DB_HOST: ${WORKER_VOICE_EMOTION_STATISTIC_DB_HOST}
            DB_PORT: ${WORKER_VOICE_EMOTION_STATISTIC_DB_PORT}
            DB_USER: ${WORKER_VOICE_EMOTION_STATISTIC_DB_USER}
            DB_PWD: ${WORKER_VOICE_EMOTION_STATISTIC_DB_PWD}
        restart: always
        depends_on:
            "mysql":
                condition: service_healthy
            "rabbitmq":
                condition: service_healthy
    # ========== Admin UI/admin UI
    voice_emotion_houta:
        image: ${VOICE_EMOTION_HOUTA_IMAGE}:${VOICE_EMOTION_HOUTA_TAG}
        container_name: ${VOICE_EMOTION_HOUTA_CONTAINER}
        ports:
            - "${VOICE_EMOTION_HOUTA_PORT}:80"
        logging:
            options:
                max-size: "${DOCKER_LOG_OPT_MAX_SIZE}"
                max-file: ${DOCKER_LOG_OPT_MAX_FILE}
        mem_limit: 2048m
        volumes:
            - /etc/localtime:/etc/localtime
        depends_on:
            "mysql":
                condition: service_healthy
        environment:
            HT_DB_HOST: ${VOICE_EMOTION_HOUTA_DB_HOST}
            HT_DB_NAME: ${VOICE_EMOTION_HOUTA_DB_NAME}
            HT_DB_ACCOUNT: ${VOICE_EMOTION_HOUTA_DB_ACCOUNT}
            HT_DB_PASSWORD: ${VOICE_EMOTION_HOUTA_DB_PASSWORD}

    # ========== NGINX ==========
    nginx:
        image: nginx
        container_name: nginx
        ports:
            - '80:80'
            - '443:443'
        logging:
            #options:
            #    max-size: "${DOCKER_LOG_OPT_MAX_SIZE}"
            #    max-file: ${DOCKER_LOG_OPT_MAX_FILE}
            driver: gelf
            options:
                gelf-address: "udp://172.17.0.1:${LOG_PORT}"
                tag: "nginx"
        mem_limit: 2048m
        volumes:
            - /etc/localtime:/etc/localtime
            - ${NGINX_CERT}:/etc/nginx/ssl/nginx.crt
            - ${NGINX_KEY}:/etc/nginx/ssl/nginx.key
            - ${NGINX_CONF}:/etc/nginx/nginx.conf
        restart: always

    # ========== Authentication =========
    authentication:
        image: ${AUTH_IMAGE}:${AUTH_TAG}
        container_name: ${AUTH_CONTAINER}
        ports:
            - "${AUTH_PORT}:${AUTH_PORT}"
        logging:
            options:
                max-size: "${DOCKER_LOG_OPT_MAX_SIZE}"
                max-file: ${DOCKER_LOG_OPT_MAX_FILE}
        mem_limit: 2048m
        volumes:
            - /etc/localtime:/etc/localtime
        environment:
            MYSQL_URL: ${AUTH_MYSQL_URL}
            MYSQL_USER: ${AUTH_MYSQL_USER}
            MYSQL_PASS: ${AUTH_MYSQL_PASS}
            MYSQL_DB: ${AUTH_MYSQL_DATABASE}
            CONSUL_URL: ${CONSUL_IP}:${CONSUL_PORT}
        restart: always
        depends_on:
            "mysql":
                condition: service_healthy
            "consul":
                condition: service_healthy
    # ========== Consul ==========
    consul:
        image: consul:${CONSUL_TAG}
        container_name: consul
        ports:
            - "${CONSUL_PORT}:${CONSUL_PORT}"
        logging:
            options:
                max-size: "${DOCKER_LOG_OPT_MAX_SIZE}"
                max-file: ${DOCKER_LOG_OPT_MAX_FILE}
        mem_limit: 2048m
        volumes:
            - /etc/localtime:/etc/localtime
            - "${CONSUL_DATA_PATH}:/consul/data"
        restart: always
        healthcheck:
            test: "curl -XGET 'http://${CONSUL_IP}:${CONSUL_PORT}/v1/health/state/critical'"
            interval: 3s
            timeout: 1s
            retries: 5
    # ========== elastic-closer
    elastic-closer:
        image: ${ESCLOSE_IMAGE}:${ESCLOSE_TAG}
        container_name: ${ESCLOSE_CONTAINER}
        logging:
            options:
                max-size: "${DOCKER_LOG_OPT_MAX_SIZE}"
                max-file: ${DOCKER_LOG_OPT_MAX_FILE}
        mem_limit: 2048m
        external_links:
            - ${ES_CONTAINER}:elasticsearch
        environment:
            ELASTIC_EXPIRE_DAYS: ${ESCLOSE_EXPIRE_DAYS}
            ELASTIC_HOST: "elasticsearch"
            ELASTIC_PORT: "${ES_PORT}"
            ELASTIC_PREFIX: ${ESCLOSE_PREFIX}
        volumes:
            - /etc/localtime:/etc/localtime

    # ========== elasticsearch
    elasticsearch:
        image: ${ES_IMAGE}:${ES_TAG}
        container_name: ${ES_CONTAINER}
        volumes:
            - /etc/localtime:/etc/localtime
            - ${ES_DATA_PATH}/data:/usr/share/elasticsearch/data
        logging:
            options:
                max-size: "${DOCKER_LOG_OPT_MAX_SIZE}"
                max-file: ${DOCKER_LOG_OPT_MAX_FILE}
        mem_limit: 2048m
    # ========== kibana
    kibana:
        image: ${KIBANA_IMAGE}:${KIBANA_TAG}
        container_name: ${KIBANA_CONTAINER}
        ports:
            - "${KIBANA_PORT}:${KIBANA_PORT}"
        external_links:
            - ${ES_CONTAINER}:elasticsearch
        logging:
            options:
                max-size: "${DOCKER_LOG_OPT_MAX_SIZE}"
                max-file: ${DOCKER_LOG_OPT_MAX_FILE}
        mem_limit: 2048m
        volumes:
            - /etc/localtime:/etc/localtime

    # ========== logstash
    logstash:
        image: ${LOG_IMAGE}:${LOG_TAG}
        container_name: ${LOG_CONTAINER}
        logging:
            options:
                max-size: "${DOCKER_LOG_OPT_MAX_SIZE}"
                max-file: ${DOCKER_LOG_OPT_MAX_FILE}
        mem_limit: 2048m
        restart: always
        external_links:
            - ${ES_CONTAINER}:elasticsearch
        ports:
            - "${LOG_PORT}:${LOG_PORT}/udp"
        depends_on:
            - "elasticsearch"
        volumes:
            - /etc/localtime:/etc/localtime
            - ${LOG_CONF}:/config-dir/logstash.conf
        command: ["/usr/share/logstash/bin/logstash", "-f", "/config-dir/logstash.conf"]
        entrypoint:
            - sh
    netdata:
        image: titpetric/netdata
        container_name: netdata
        mem_limit: 2048m
        ports:
            - "${NETDATA_PORT}:${NETDATA_PORT}"
        logging:
            options:
                max-size: "${DOCKER_LOG_OPT_MAX_SIZE}"
                max-file: ${DOCKER_LOG_OPT_MAX_FILE}
        volumes:
            - /etc/localtime:/etc/localtime
            - ${NETDATA_HEALTH_ALARM_NOTIFY_CONF}:/etc/netdata/health_alarm_notify.conf
            - /proc:/host/proc:ro
            - /sys:/host/sys:ro
            - /var/run/docker.sock:/var/run/docker.sock
        restart: always
    bf-ubt-apigw:
        image: ${BF_UBT_APIGW_IMAGE}:${BF_UBT_APIGW_TAG}
        container_name: ${BF_UBT_APIGW_CONTAINER}
        ports:
            - "${BF_UBT_APIGW_PORT}:${BF_UBT_APIGW_PORT}"
        logging:
            options:
                max-size: "${DOCKER_LOG_OPT_MAX_SIZE}"
                max-file: ${DOCKER_LOG_OPT_MAX_FILE}
        environment:
            DOCKER_PORT: ${BF_UBT_APIGW_PORT}
            BF_API_URL: ${BF_API_URL}
            BF_LEVEL_API_URL: ${BF_LEVEL_API_URL}
            KG_API_URL: ${KG_API_URL}
        mem_limit: 2048m
        volumes:
            - /etc/localtime:/etc/localtime
        depends_on:
            - nginx
        restart: always

